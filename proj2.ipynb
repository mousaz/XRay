{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea3d6755-854a-4d47-86a6-62cc29ac39cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\ANNU-10\\.cache\\kagglehub\\datasets\\raddar\\chest-xrays-indiana-university\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"raddar/chest-xrays-indiana-university\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9f3a88f-3e38-4100-9187-2ebcce62d8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "2.7.1+cu128\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "519df1e8-9c8d-4111-bdf3-889654a5a0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7466 entries, 0 to 7465\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   uid         7466 non-null   int64 \n",
      " 1   filename    7466 non-null   object\n",
      " 2   projection  7466 non-null   object\n",
      " 3   MeSH        7466 non-null   object\n",
      " 4   Problems    7466 non-null   object\n",
      " 5   image       7466 non-null   object\n",
      " 6   indication  7466 non-null   object\n",
      " 7   comparison  7466 non-null   object\n",
      " 8   findings    7466 non-null   object\n",
      " 9   impression  7466 non-null   object\n",
      " 10  report      7466 non-null   object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 641.7+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "dataset_folder = path\n",
    "images_folder = dataset_folder + \"/images/images_normalized\"\n",
    "projections = pandas.read_csv(dataset_folder + \"/indiana_projections.csv\")\n",
    "reports = pandas.read_csv(dataset_folder + \"/indiana_reports.csv\")\n",
    "\n",
    "combined_dataset = projections.merge(reports, on=\"uid\", how=\"inner\")\n",
    "\n",
    "def IsNotAvailable(value):\n",
    "    return value.str.contains(\"unavailable\", case=False, na=False) \\\n",
    "        | value.str.contains(\"not available\", case=False, na=False) \\\n",
    "        | value.str.contains(\"none\", case=False, na=False)\n",
    "\n",
    "combined_dataset.loc[IsNotAvailable(combined_dataset[\"comparison\"]), \"comparison\"] = \"None\"\n",
    "\n",
    "combined_dataset[\"indication\"] = combined_dataset[\"indication\"].fillna(\"None\")\n",
    "combined_dataset[\"findings\"] = combined_dataset[\"findings\"].fillna(\"None\")\n",
    "combined_dataset[\"impression\"] = combined_dataset[\"impression\"].fillna(\"None\")\n",
    "combined_dataset[\"comparison\"] = combined_dataset[\"comparison\"].fillna(\"None\")\n",
    "combined_dataset[\"report\"] = (\n",
    "    \"Indication: \" + combined_dataset[\"indication\"].astype(str) + \"\\n\"\n",
    "    + \"Findings: \" + combined_dataset[\"findings\"].astype(str) + \"\\n\"\n",
    "    + \"Impression: \" + combined_dataset[\"impression\"].astype(str) + \"\\n\"\n",
    "    + \"Comparison: \" + combined_dataset[\"comparison\"].astype(str)\n",
    ")\n",
    "\n",
    "combined_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "474f63a2-d32a-473e-888d-f9fe4fa318f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>filename</th>\n",
       "      <th>projection</th>\n",
       "      <th>MeSH</th>\n",
       "      <th>Problems</th>\n",
       "      <th>image</th>\n",
       "      <th>indication</th>\n",
       "      <th>comparison</th>\n",
       "      <th>findings</th>\n",
       "      <th>impression</th>\n",
       "      <th>report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1_IM-0001-4001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>Xray Chest PA and Lateral</td>\n",
       "      <td>Positive TB test</td>\n",
       "      <td>None</td>\n",
       "      <td>The cardiac silhouette and mediastinum size ar...</td>\n",
       "      <td>Normal chest x-XXXX.</td>\n",
       "      <td>Indication: Positive TB test\\nFindings: The ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1_IM-0001-3001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>Xray Chest PA and Lateral</td>\n",
       "      <td>Positive TB test</td>\n",
       "      <td>None</td>\n",
       "      <td>The cardiac silhouette and mediastinum size ar...</td>\n",
       "      <td>Normal chest x-XXXX.</td>\n",
       "      <td>Indication: Positive TB test\\nFindings: The ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2_IM-0652-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>Cardiomegaly/borderline;Pulmonary Artery/enlarged</td>\n",
       "      <td>Cardiomegaly;Pulmonary Artery</td>\n",
       "      <td>Chest, 2 views, frontal and lateral</td>\n",
       "      <td>Preop bariatric surgery.</td>\n",
       "      <td>None</td>\n",
       "      <td>Borderline cardiomegaly. Midline sternotomy XX...</td>\n",
       "      <td>No acute pulmonary findings.</td>\n",
       "      <td>Indication: Preop bariatric surgery.\\nFindings...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2_IM-0652-2001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "      <td>Cardiomegaly/borderline;Pulmonary Artery/enlarged</td>\n",
       "      <td>Cardiomegaly;Pulmonary Artery</td>\n",
       "      <td>Chest, 2 views, frontal and lateral</td>\n",
       "      <td>Preop bariatric surgery.</td>\n",
       "      <td>None</td>\n",
       "      <td>Borderline cardiomegaly. Midline sternotomy XX...</td>\n",
       "      <td>No acute pulmonary findings.</td>\n",
       "      <td>Indication: Preop bariatric surgery.\\nFindings...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3_IM-1384-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>Xray Chest PA and Lateral</td>\n",
       "      <td>rib pain after a XXXX, XXXX XXXX steps this XX...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No displaced rib fractures, pneumothorax, or p...</td>\n",
       "      <td>Indication: rib pain after a XXXX, XXXX XXXX s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid                filename projection  \\\n",
       "0    1  1_IM-0001-4001.dcm.png    Frontal   \n",
       "1    1  1_IM-0001-3001.dcm.png    Lateral   \n",
       "2    2  2_IM-0652-1001.dcm.png    Frontal   \n",
       "3    2  2_IM-0652-2001.dcm.png    Lateral   \n",
       "4    3  3_IM-1384-1001.dcm.png    Frontal   \n",
       "\n",
       "                                                MeSH  \\\n",
       "0                                             normal   \n",
       "1                                             normal   \n",
       "2  Cardiomegaly/borderline;Pulmonary Artery/enlarged   \n",
       "3  Cardiomegaly/borderline;Pulmonary Artery/enlarged   \n",
       "4                                             normal   \n",
       "\n",
       "                        Problems                                image  \\\n",
       "0                         normal            Xray Chest PA and Lateral   \n",
       "1                         normal            Xray Chest PA and Lateral   \n",
       "2  Cardiomegaly;Pulmonary Artery  Chest, 2 views, frontal and lateral   \n",
       "3  Cardiomegaly;Pulmonary Artery  Chest, 2 views, frontal and lateral   \n",
       "4                         normal            Xray Chest PA and Lateral   \n",
       "\n",
       "                                          indication comparison  \\\n",
       "0                                   Positive TB test       None   \n",
       "1                                   Positive TB test       None   \n",
       "2                           Preop bariatric surgery.       None   \n",
       "3                           Preop bariatric surgery.       None   \n",
       "4  rib pain after a XXXX, XXXX XXXX steps this XX...       None   \n",
       "\n",
       "                                            findings  \\\n",
       "0  The cardiac silhouette and mediastinum size ar...   \n",
       "1  The cardiac silhouette and mediastinum size ar...   \n",
       "2  Borderline cardiomegaly. Midline sternotomy XX...   \n",
       "3  Borderline cardiomegaly. Midline sternotomy XX...   \n",
       "4                                               None   \n",
       "\n",
       "                                          impression  \\\n",
       "0                               Normal chest x-XXXX.   \n",
       "1                               Normal chest x-XXXX.   \n",
       "2                       No acute pulmonary findings.   \n",
       "3                       No acute pulmonary findings.   \n",
       "4  No displaced rib fractures, pneumothorax, or p...   \n",
       "\n",
       "                                              report  \n",
       "0  Indication: Positive TB test\\nFindings: The ca...  \n",
       "1  Indication: Positive TB test\\nFindings: The ca...  \n",
       "2  Indication: Preop bariatric surgery.\\nFindings...  \n",
       "3  Indication: Preop bariatric surgery.\\nFindings...  \n",
       "4  Indication: rib pain after a XXXX, XXXX XXXX s...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddb36be8-9fbc-4042-b5e4-7b8ec60b24be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indication: Positive TB test\n",
      "Findings: The cardiac silhouette and mediastinum size are within normal limits. There is no pulmonary edema. There is no focal consolidation. There are no XXXX of a pleural effusion. There is no evidence of pneumothorax.\n",
      "Impression: Normal chest x-XXXX.\n",
      "Comparison: None\n",
      "-----\n",
      "Indication: Positive TB test\n",
      "Findings: The cardiac silhouette and mediastinum size are within normal limits. There is no pulmonary edema. There is no focal consolidation. There are no XXXX of a pleural effusion. There is no evidence of pneumothorax.\n",
      "Impression: Normal chest x-XXXX.\n",
      "Comparison: None\n",
      "-----\n",
      "Indication: Preop bariatric surgery.\n",
      "Findings: Borderline cardiomegaly. Midline sternotomy XXXX. Enlarged pulmonary arteries. Clear lungs. Inferior XXXX XXXX XXXX.\n",
      "Impression: No acute pulmonary findings.\n",
      "Comparison: None\n",
      "-----\n",
      "Indication: Preop bariatric surgery.\n",
      "Findings: Borderline cardiomegaly. Midline sternotomy XXXX. Enlarged pulmonary arteries. Clear lungs. Inferior XXXX XXXX XXXX.\n",
      "Impression: No acute pulmonary findings.\n",
      "Comparison: None\n",
      "-----\n",
      "Indication: rib pain after a XXXX, XXXX XXXX steps this XXXX. Pain to R back, R elbow and R rib XXXX, no previous heart or lung hx, non-XXXX, no hx ca\n",
      "Findings: None\n",
      "Impression: No displaced rib fractures, pneumothorax, or pleural effusion identified. Well-expanded and clear lungs. Mediastinal contour within normal limits. No acute cardiopulmonary abnormality identified.\n",
      "Comparison: None\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "for r in combined_dataset[\"report\"].head(5).to_list():\n",
    "    print(r)\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38dc98a7-2abb-4a08-b760-76b2155711e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (5972, 11), Test shape: (1494, 11)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(combined_dataset, test_size=0.2, random_state=42, shuffle=True)\n",
    "print(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a7ea0e1-8f31-478c-9699-b275e024ee17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2-VIT-CrossAtten: GPT-2 hidden size: 768, ViT hidden size: 768\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import GPT2Model, GPT2LMHeadModel, GPT2Tokenizer, ViTModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# GPT-2 with Cross-Attention\n",
    "class GPT2WithCrossAttention(nn.Module):\n",
    "    def __init__(self, gpt2_model, vit_model, gpt2_hidden_size, vit_hidden_size):\n",
    "        super(GPT2WithCrossAttention, self).__init__()\n",
    "        \n",
    "        # Load pre-trained GPT2 model\n",
    "        self.gpt2 = gpt2_model\n",
    "        \n",
    "        # Load pre-trained Vision Transformer model\n",
    "        self.vit = vit_model\n",
    "        \n",
    "        # Cross-attention layer (between ViT and GPT2)\n",
    "        self.cross_attention = nn.MultiheadAttention(embed_dim=gpt2_hidden_size, num_heads=8, batch_first=True)\n",
    "        \n",
    "        # Linear layer to project ViT features into GPT2 hidden size\n",
    "        self.image_projection = nn.Linear(vit_hidden_size, gpt2_hidden_size)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, images):\n",
    "        # Get the image embeddings (from ViT)\n",
    "        image_features = self.vit(images).last_hidden_state  # Shape: (batch_size, num_patches, vit_hidden_size)\n",
    "        \n",
    "        # Project image features to match GPT-2 hidden size\n",
    "        image_features = image_features.mean(dim=1)  # Shape: (batch_size, vit_hidden_size)\n",
    "        image_features = self.image_projection(image_features)  # Shape: (batch_size, gpt2_hidden_size)\n",
    "\n",
    "        # Get GPT2 embeddings (language embeddings)\n",
    "        gpt2_outputs = self.gpt2(input_ids=input_ids, attention_mask=attention_mask, return_dict=True, output_hidden_states=True)\n",
    "        gpt2_hidden_states = gpt2_outputs.hidden_states[-1]  # Shape: (batch_size, seq_len, gpt2_hidden_size)\n",
    "\n",
    "        # Cross-attention: GPT-2 attending to ViT embeddings\n",
    "        # We concatenate the image features to the sequence of tokens in GPT-2\n",
    "        image_features = image_features.unsqueeze(1).repeat(1, gpt2_hidden_states.size(1), 1)  # Broadcast image features\n",
    "        \n",
    "        # Apply multi-head attention (cross-attention) between GPT-2 hidden states and image features\n",
    "        attn_output, attn_weights = self.cross_attention(query=gpt2_hidden_states, key=image_features, value=image_features)\n",
    "        \n",
    "        # Combine the attention output with GPT-2 hidden states\n",
    "        combined_output = attn_output + gpt2_hidden_states  # Residual connection\n",
    "\n",
    "        logits = self.gpt2.lm_head(combined_output)  # Project to vocabulary size\n",
    "        \n",
    "        return logits\n",
    "\n",
    "# Define dataset\n",
    "class XRayReportDataset(Dataset):\n",
    "    def __init__(self, data, transform=None, tokenizer=None, max_length=512):\n",
    "        self.data = data\n",
    "        self.images_folder = images_folder\n",
    "        self.image_paths = data[\"filename\"].apply(lambda x: os.path.join(images_folder, x)).tolist()\n",
    "        self.reports = data[\"report\"].tolist()\n",
    "        self.transform = transform\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        report = self.reports[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        \n",
    "        # Apply transformations (if any)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Tokenize text (report)\n",
    "        inputs = self.tokenizer(report, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        \n",
    "        return image, inputs.input_ids.squeeze(), inputs.attention_mask.squeeze()\n",
    "\n",
    "# Load ViT and GPT-2 models\n",
    "vit_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token  # Set pad token to eos token for GPT-2\n",
    "\n",
    "# Set models to eval mode\n",
    "vit_model.eval()\n",
    "gpt2_model.eval()\n",
    "\n",
    "# Prepare dataset and dataloaders\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define the custom GPT-2 model with cross-attention\n",
    "hidden_size = gpt2_model.config.hidden_size\n",
    "image_feature_size = vit_model.config.hidden_size  # Image features from ViT are the same size as GPT-2 hidden states\n",
    "gpt2_vit_with_cross_att_model = GPT2WithCrossAttention(gpt2_model, vit_model, hidden_size, image_feature_size).to(device)\n",
    "\n",
    "print(f\"GPT2-VIT-CrossAtten: GPT-2 hidden size: {hidden_size}, ViT hidden size: {image_feature_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d18aebc-0abf-4834-a561-de7b3e3ef289",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1493/1493 [17:23<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.0053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1493/1493 [17:20<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Loss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1493/1493 [17:21<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Loss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1493/1493 [17:20<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Loss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1493/1493 [17:20<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, ViTModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 4\n",
    "epochs = 5\n",
    "learning_rate = 5e-5\n",
    "max_length = 512  # GPT-2 max length for tokenized reports\n",
    "\n",
    "train_dataset = XRayReportDataset(train_df, transform, gpt2_tokenizer, max_length)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = torch.optim.AdamW(gpt2_vit_with_cross_att_model.parameters(), lr=learning_rate)\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    gpt2_vit_with_cross_att_model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (images, input_ids, attention_mask) in enumerate(tqdm(train_dataloader)):\n",
    "        images = images.to(device)\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = gpt2_vit_with_cross_att_model(input_ids=input_ids, attention_mask=attention_mask, images=images)\n",
    "        logits = outputs  # Shape: (batch_size, seq_length, vocab_size)\n",
    "\n",
    "        # Calculate loss (using the labels as the input_ids)\n",
    "        labels = input_ids  # Labels are the same as the input_ids\n",
    "        loss = criterion(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(train_dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Optionally, save model after each epoch\n",
    "    torch.save(gpt2_vit_with_cross_att_model.state_dict(), f\"training/gpt2_vit_cross_attention/epoch_{(epoch + 1):02d}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5551d62-0b6e-446d-b990-ed029bc2de64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ANNU-10\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "C:\\Users\\ANNU-10\\AppData\\Roaming\\Python\\Python313\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\ANNU-10\\AppData\\Roaming\\Python\\Python313\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.0000\n",
      "ROUGE-1: 0.0142, ROUGE-2: 0.0000, ROUGE-L: 0.0131\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
    "from rouge_score import rouge_scorer\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "58218ce1-e5ab-4513-880e-fc484dfd907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a report from an image\n",
    "def generate_report_from_image(model, image, tokenizer, device):\n",
    "    model.eval()\n",
    "    \n",
    "    image = image.unsqueeze(0).to(device) # Adding a dummy batch dimmension\n",
    "    input_ids = tokenizer.encode(\"Findings:\", return_tensors=\"pt\").to(device)\n",
    "    attention_mask = torch.ones(input_ids.shape, device=device)\n",
    "    \n",
    "    # Generate a report\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids=input_ids, attention_mask=attention_mask, images=image)\n",
    "    \n",
    "    generated_ids = torch.argmax(output, dim=-1)\n",
    "    generated_report = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return generated_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48797fe-7945-473e-a980-78395ba6013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate BLEU score\n",
    "def compute_bleu(reference_texts, generated_texts):\n",
    "    \"\"\"\n",
    "    Compute BLEU score between generated texts and references.\n",
    "    \n",
    "    :param reference_texts: List of lists of reference texts (for each generated report)\n",
    "    :param generated_texts: List of generated reports\n",
    "    :return: BLEU score\n",
    "    \"\"\"\n",
    "    references = [[ref.split()] for ref in reference_texts]  # List of list of reference tokens\n",
    "    candidates = [gen.split() for gen in generated_texts]   # List of list of generated tokens\n",
    "    bleu_score = corpus_bleu(references, candidates)\n",
    "    return bleu_score\n",
    "\n",
    "# Function to calculate ROUGE score\n",
    "def compute_rouge(reference_texts, generated_texts):\n",
    "    \"\"\"\n",
    "    Compute ROUGE score between generated texts and references.\n",
    "    \n",
    "    :param reference_texts: List of reference reports\n",
    "    :param generated_texts: List of generated reports\n",
    "    :return: ROUGE score\n",
    "    \"\"\"\n",
    "    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
    "    rouge_scores = {\"rouge1\": [], \"rouge2\": [], \"rougeL\": []}\n",
    "    \n",
    "    for reference, generated in zip(reference_texts, generated_texts):\n",
    "        scores = scorer.score(reference, generated)\n",
    "        for key in rouge_scores:\n",
    "            rouge_scores[key].append(scores[key].fmeasure)\n",
    "    \n",
    "    avg_rouge1 = sum(rouge_scores[\"rouge1\"]) / len(rouge_scores[\"rouge1\"])\n",
    "    avg_rouge2 = sum(rouge_scores[\"rouge2\"]) / len(rouge_scores[\"rouge2\"])\n",
    "    avg_rougeL = sum(rouge_scores[\"rougeL\"]) / len(rouge_scores[\"rougeL\"])\n",
    "    \n",
    "    return avg_rouge1, avg_rouge2, avg_rougeL\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, dataloader, tokenizer, device):\n",
    "    generated_reports = []\n",
    "    reference_reports = []\n",
    "    \n",
    "    # Collect ground truth reports and generated reports\n",
    "    for images, input_ids, attention_mask in dataloader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "\n",
    "        for i, image in enumerate(images):\n",
    "            # Generate report for each image\n",
    "            generated_report = generate_report_from_image(model, image, tokenizer, device)\n",
    "            reference_report = tokenizer.decode(input_ids[i], skip_special_tokens=True)\n",
    "            \n",
    "            generated_reports.append(generated_report)\n",
    "            reference_reports.append(reference_report)\n",
    "    \n",
    "    # Compute BLEU\n",
    "    bleu_score = compute_bleu(reference_reports, generated_reports)\n",
    "    print(f\"BLEU Score: {bleu_score:.4f}\")\n",
    "    \n",
    "    # Compute ROUGE\n",
    "    rouge1, rouge2, rougeL = compute_rouge(reference_reports, generated_reports)\n",
    "    print(f\"ROUGE-1: {rouge1:.4f}, ROUGE-2: {rouge2:.4f}, ROUGE-L: {rougeL:.4f}\")\n",
    "\n",
    "# Define the dataloader for eevaluation\n",
    "test_dataset = XRayReportDataset(test_df, transform, gpt2_tokenizer, max_length)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "gpt2_vit_with_cross_att_model.to(device)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(gpt2_vit_with_cross_att_model, test_dataloader, gpt2_tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0b95e7d7-df11-404c-8b70-3f20a58dc9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Report:\n",
      "------------\n",
      "Indication: Preop bariatric surgery.\n",
      "Findings: Borderline cardiomegaly. Midline sternotomy XXXX. Enlarged pulmonary arteries. Clear lungs. Inferior XXXX XXXX XXXX.\n",
      "Impression: No acute pulmonary findings.\n",
      "Comparison: None\n",
      "------------\n",
      "Predicted Report:\n",
      "------------\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "index = 3\n",
    "image_path = os.path.join(images_folder, combined_dataset.loc[index, \"filename\"])\n",
    "image = transform(Image.open(image_path).convert(\"RGB\"))\n",
    "print(\"Actual Report:\\n------------\")\n",
    "print(combined_dataset.loc[index, \"report\"])\n",
    "print(\"------------\")\n",
    "print(\"Predicted Report:\\n------------\")\n",
    "generate_report_from_image(gpt2_vit_with_cross_att_model, image, gpt2_tokenizer, device)\n",
    "print(\"------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7246e243-8940-43f5-8b9f-ba0044db4952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
