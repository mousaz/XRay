{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "985ae95a-e38e-416b-8b10-b8bb5aea287d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\ANNU-10\\.cache\\kagglehub\\datasets\\raddar\\chest-xrays-indiana-university\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"raddar/chest-xrays-indiana-university\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5e7de6c-8e0c-4647-b2a2-84deb043183a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "2.7.1+cu128\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b271840-7de2-45eb-b507-a8048f4c7eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7466 entries, 0 to 7465\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   uid         7466 non-null   int64 \n",
      " 1   filename    7466 non-null   object\n",
      " 2   projection  7466 non-null   object\n",
      " 3   MeSH        7466 non-null   object\n",
      " 4   Problems    7466 non-null   object\n",
      " 5   image       7466 non-null   object\n",
      " 6   indication  7466 non-null   object\n",
      " 7   comparison  7466 non-null   object\n",
      " 8   findings    7466 non-null   object\n",
      " 9   impression  7466 non-null   object\n",
      " 10  report      7466 non-null   object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 641.7+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "dataset_folder = path\n",
    "images_folder = dataset_folder + \"/images/images_normalized\"\n",
    "projections = pandas.read_csv(dataset_folder + \"/indiana_projections.csv\")\n",
    "reports = pandas.read_csv(dataset_folder + \"/indiana_reports.csv\")\n",
    "\n",
    "combined_dataset = projections.merge(reports, on=\"uid\", how=\"inner\")\n",
    "\n",
    "def IsNotAvailable(value):\n",
    "    return value.str.contains(\"unavailable\", case=False, na=False) \\\n",
    "        | value.str.contains(\"not available\", case=False, na=False) \\\n",
    "        | value.str.contains(\"none\", case=False, na=False)\n",
    "\n",
    "combined_dataset.loc[IsNotAvailable(combined_dataset[\"comparison\"]), \"comparison\"] = \"None\"\n",
    "\n",
    "combined_dataset[\"indication\"] = combined_dataset[\"indication\"].fillna(\"None\")\n",
    "combined_dataset[\"findings\"] = combined_dataset[\"findings\"].fillna(\"None\")\n",
    "combined_dataset[\"impression\"] = combined_dataset[\"impression\"].fillna(\"None\")\n",
    "combined_dataset[\"comparison\"] = combined_dataset[\"comparison\"].fillna(\"None\")\n",
    "combined_dataset[\"report\"] = (\n",
    "    \"Indication: \" + combined_dataset[\"indication\"].astype(str) + \"\\n\"\n",
    "    + \"Findings: \" + combined_dataset[\"findings\"].astype(str) + \"\\n\"\n",
    "    + \"Impression: \" + combined_dataset[\"impression\"].astype(str) + \"\\n\"\n",
    "    + \"Comparison: \" + combined_dataset[\"comparison\"].astype(str)\n",
    ")\n",
    "\n",
    "combined_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab78264b-de5c-4723-9a78-d9e3d7c82c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>filename</th>\n",
       "      <th>projection</th>\n",
       "      <th>MeSH</th>\n",
       "      <th>Problems</th>\n",
       "      <th>image</th>\n",
       "      <th>indication</th>\n",
       "      <th>comparison</th>\n",
       "      <th>findings</th>\n",
       "      <th>impression</th>\n",
       "      <th>report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1_IM-0001-4001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>Xray Chest PA and Lateral</td>\n",
       "      <td>Positive TB test</td>\n",
       "      <td>None</td>\n",
       "      <td>The cardiac silhouette and mediastinum size ar...</td>\n",
       "      <td>Normal chest x-XXXX.</td>\n",
       "      <td>Indication: Positive TB test\\nFindings: The ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1_IM-0001-3001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>Xray Chest PA and Lateral</td>\n",
       "      <td>Positive TB test</td>\n",
       "      <td>None</td>\n",
       "      <td>The cardiac silhouette and mediastinum size ar...</td>\n",
       "      <td>Normal chest x-XXXX.</td>\n",
       "      <td>Indication: Positive TB test\\nFindings: The ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2_IM-0652-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>Cardiomegaly/borderline;Pulmonary Artery/enlarged</td>\n",
       "      <td>Cardiomegaly;Pulmonary Artery</td>\n",
       "      <td>Chest, 2 views, frontal and lateral</td>\n",
       "      <td>Preop bariatric surgery.</td>\n",
       "      <td>None</td>\n",
       "      <td>Borderline cardiomegaly. Midline sternotomy XX...</td>\n",
       "      <td>No acute pulmonary findings.</td>\n",
       "      <td>Indication: Preop bariatric surgery.\\nFindings...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2_IM-0652-2001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "      <td>Cardiomegaly/borderline;Pulmonary Artery/enlarged</td>\n",
       "      <td>Cardiomegaly;Pulmonary Artery</td>\n",
       "      <td>Chest, 2 views, frontal and lateral</td>\n",
       "      <td>Preop bariatric surgery.</td>\n",
       "      <td>None</td>\n",
       "      <td>Borderline cardiomegaly. Midline sternotomy XX...</td>\n",
       "      <td>No acute pulmonary findings.</td>\n",
       "      <td>Indication: Preop bariatric surgery.\\nFindings...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3_IM-1384-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>Xray Chest PA and Lateral</td>\n",
       "      <td>rib pain after a XXXX, XXXX XXXX steps this XX...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No displaced rib fractures, pneumothorax, or p...</td>\n",
       "      <td>Indication: rib pain after a XXXX, XXXX XXXX s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid                filename projection  \\\n",
       "0    1  1_IM-0001-4001.dcm.png    Frontal   \n",
       "1    1  1_IM-0001-3001.dcm.png    Lateral   \n",
       "2    2  2_IM-0652-1001.dcm.png    Frontal   \n",
       "3    2  2_IM-0652-2001.dcm.png    Lateral   \n",
       "4    3  3_IM-1384-1001.dcm.png    Frontal   \n",
       "\n",
       "                                                MeSH  \\\n",
       "0                                             normal   \n",
       "1                                             normal   \n",
       "2  Cardiomegaly/borderline;Pulmonary Artery/enlarged   \n",
       "3  Cardiomegaly/borderline;Pulmonary Artery/enlarged   \n",
       "4                                             normal   \n",
       "\n",
       "                        Problems                                image  \\\n",
       "0                         normal            Xray Chest PA and Lateral   \n",
       "1                         normal            Xray Chest PA and Lateral   \n",
       "2  Cardiomegaly;Pulmonary Artery  Chest, 2 views, frontal and lateral   \n",
       "3  Cardiomegaly;Pulmonary Artery  Chest, 2 views, frontal and lateral   \n",
       "4                         normal            Xray Chest PA and Lateral   \n",
       "\n",
       "                                          indication comparison  \\\n",
       "0                                   Positive TB test       None   \n",
       "1                                   Positive TB test       None   \n",
       "2                           Preop bariatric surgery.       None   \n",
       "3                           Preop bariatric surgery.       None   \n",
       "4  rib pain after a XXXX, XXXX XXXX steps this XX...       None   \n",
       "\n",
       "                                            findings  \\\n",
       "0  The cardiac silhouette and mediastinum size ar...   \n",
       "1  The cardiac silhouette and mediastinum size ar...   \n",
       "2  Borderline cardiomegaly. Midline sternotomy XX...   \n",
       "3  Borderline cardiomegaly. Midline sternotomy XX...   \n",
       "4                                               None   \n",
       "\n",
       "                                          impression  \\\n",
       "0                               Normal chest x-XXXX.   \n",
       "1                               Normal chest x-XXXX.   \n",
       "2                       No acute pulmonary findings.   \n",
       "3                       No acute pulmonary findings.   \n",
       "4  No displaced rib fractures, pneumothorax, or p...   \n",
       "\n",
       "                                              report  \n",
       "0  Indication: Positive TB test\\nFindings: The ca...  \n",
       "1  Indication: Positive TB test\\nFindings: The ca...  \n",
       "2  Indication: Preop bariatric surgery.\\nFindings...  \n",
       "3  Indication: Preop bariatric surgery.\\nFindings...  \n",
       "4  Indication: rib pain after a XXXX, XXXX XXXX s...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b402a01e-f067-4d2a-bad0-aabb2b3679c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indication: Positive TB test\n",
      "Findings: The cardiac silhouette and mediastinum size are within normal limits. There is no pulmonary edema. There is no focal consolidation. There are no XXXX of a pleural effusion. There is no evidence of pneumothorax.\n",
      "Impression: Normal chest x-XXXX.\n",
      "Comparison: None\n",
      "-----\n",
      "Indication: Positive TB test\n",
      "Findings: The cardiac silhouette and mediastinum size are within normal limits. There is no pulmonary edema. There is no focal consolidation. There are no XXXX of a pleural effusion. There is no evidence of pneumothorax.\n",
      "Impression: Normal chest x-XXXX.\n",
      "Comparison: None\n",
      "-----\n",
      "Indication: Preop bariatric surgery.\n",
      "Findings: Borderline cardiomegaly. Midline sternotomy XXXX. Enlarged pulmonary arteries. Clear lungs. Inferior XXXX XXXX XXXX.\n",
      "Impression: No acute pulmonary findings.\n",
      "Comparison: None\n",
      "-----\n",
      "Indication: Preop bariatric surgery.\n",
      "Findings: Borderline cardiomegaly. Midline sternotomy XXXX. Enlarged pulmonary arteries. Clear lungs. Inferior XXXX XXXX XXXX.\n",
      "Impression: No acute pulmonary findings.\n",
      "Comparison: None\n",
      "-----\n",
      "Indication: rib pain after a XXXX, XXXX XXXX steps this XXXX. Pain to R back, R elbow and R rib XXXX, no previous heart or lung hx, non-XXXX, no hx ca\n",
      "Findings: None\n",
      "Impression: No displaced rib fractures, pneumothorax, or pleural effusion identified. Well-expanded and clear lungs. Mediastinal contour within normal limits. No acute cardiopulmonary abnormality identified.\n",
      "Comparison: None\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "for r in combined_dataset[\"report\"].head(5).to_list():\n",
    "    print(r)\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d722ffd5-3405-4e5b-ae64-242a42115c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (5972, 11), Test shape: (1494, 11)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(combined_dataset, test_size=0.2, random_state=42, shuffle=True)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "print(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2230567e-57c4-4d2b-a0c0-79cb4898e589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "\n",
    "class MIMICDataset(Dataset):\n",
    "    def __init__(self, dataset, img_dir, tokenizer, transform=None):\n",
    "        self.data = dataset\n",
    "        self.img_dir = img_dir\n",
    "        self.tokenizer = tokenizer\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, self.data.loc[idx, \"filename\"])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        report = self.data.loc[idx, \"report\"]\n",
    "        inputs = self.tokenizer(report, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=512)\n",
    "        return image, inputs['input_ids'].squeeze(), inputs['attention_mask'].squeeze()\n",
    "\n",
    "class ResNetGPT2ReportGenerator(nn.Module):\n",
    "    def __init__(self, gpt2_model_name='gpt2', resnet_model_name='resnet50', device='cuda'):\n",
    "        super(ResNetGPT2ReportGenerator, self).__init__()\n",
    "        self.gpt2 = GPT2LMHeadModel.from_pretrained(gpt2_model_name)\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(gpt2_model_name)\n",
    "        resnet = getattr(models, resnet_model_name)(pretrained=True)\n",
    "        self.resnet = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        self.resnet_fc = nn.Linear(resnet.fc.in_features, self.gpt2.config.n_embd)\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, images, input_ids, attention_mask):\n",
    "        with torch.no_grad():\n",
    "            image_features = self.resnet(images).view(images.size(0), -1)\n",
    "        image_features = self.resnet_fc(image_features)\n",
    "        outputs = self.gpt2(input_ids=input_ids, attention_mask=attention_mask, return_dict=True, output_hidden_states=True)\n",
    "        hidden_states = outputs.hidden_states[-1]\n",
    "        image_features = image_features.unsqueeze(1).repeat(1, hidden_states.size(1), 1)\n",
    "        # combined_features = torch.cat((hidden_states, image_features), dim=-1)\n",
    "        combined_features = hidden_states + image_features\n",
    "        logits = self.gpt2.lm_head(combined_features)\n",
    "        return logits\n",
    "\n",
    "    def generate_report(self, image, max_length=100):\n",
    "        image = image.unsqueeze(0).to(self.device)\n",
    "        input_ids = torch.tensor(self.tokenizer.encode(\"Indication:\")).unsqueeze(0).to(self.device)\n",
    "        attention_mask = torch.ones(input_ids.shape, device=self.device)\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for _ in range(max_length):\n",
    "                logits = self(image, input_ids, attention_mask)\n",
    "                next_token_id = torch.argmax(logits[:, -1, :], dim=-1).unsqueeze(-1)\n",
    "                input_ids = torch.cat((input_ids, next_token_id), dim=1)\n",
    "                attention_mask = torch.cat((attention_mask, torch.ones_like(next_token_id)), dim=1)\n",
    "                if next_token_id.item() == self.tokenizer.encode(\"end\")[0]:\n",
    "                    break\n",
    "        generated_report = self.tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "        return generated_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf73355f-a21d-4f8c-ad4a-bd585fc410b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "def train(model, train_loader, val_loader, epochs=3, lr=5e-5):\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "    total_steps = len(train_loader) * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for images, input_ids, attention_mask in train_loader:\n",
    "            images = images.to(model.device)\n",
    "            input_ids = input_ids.to(model.device)\n",
    "            attention_mask = attention_mask.to(model.device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(images, input_ids, attention_mask)\n",
    "            loss = criterion(logits.view(-1, logits.size(-1)), input_ids.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "        evaluate(model, val_loader)\n",
    "\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        for images, input_ids, attention_mask in val_loader:\n",
    "            images = images.to(model.device)\n",
    "            input_ids = input_ids.to(model.device)\n",
    "            attention_mask = attention_mask.to(model.device)\n",
    "            logits = model(images, input_ids, attention_mask)\n",
    "            loss = criterion(logits.view(-1, logits.size(-1)), input_ids.view(-1))\n",
    "            total_loss += loss.item()\n",
    "    print(f\"Validation Loss: {total_loss / len(val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e7c3d9-35c8-49aa-8dac-c7620a034335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 6.477251008618623e-05\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import GPT2Tokenizer\n",
    "from torchvision import transforms\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = MIMICDataset(train_df, img_dir=images_folder, tokenizer=tokenizer, transform=transform)\n",
    "val_dataset = MIMICDataset(test_df, img_dir=images_folder, tokenizer=tokenizer, transform=transform)\n",
    "\n",
    "batch_size = 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = ResNetGPT2ReportGenerator(device=device)\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "train(model, train_loader, val_loader, epochs=3, lr=5e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc0dd1e-ee42-41b0-a75f-79158216d2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
